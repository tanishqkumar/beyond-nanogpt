{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "let's do a3c in pure torch + mp on cpus\n",
    "torch.share_memory the global params \n",
    "nstates = 3, nactions is a scalar in [-2, 2]\n",
    "we want to train a policy to maximize reward\n",
    "since we are doing actor-critic, we also need a value net \n",
    "and the loss on each batch is like ppo but without clipping? \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first just split workers, make each do independent matmuls and write to a shared counter \n",
    "import multiprocessing as mp \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import os \n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "\n",
    "def worker_matmul(counter, n=50): \n",
    "    A = torch.randn(n, n)\n",
    "    B = torch.randn(n, n)\n",
    "    A @ B\n",
    "    \n",
    "    # update shared mem \n",
    "    with counter.get_lock(): \n",
    "        counter.value += 1\n",
    "\n",
    "def worker_loop(counter, nops, n=16):\n",
    "    # Keep doing matrix multiplications until counter reaches NOPS\n",
    "    while True:\n",
    "        worker_matmul(counter, n)\n",
    "        with counter.get_lock():\n",
    "            if counter.value >= nops:\n",
    "                break\n",
    "\n",
    "def run_mp(nops, n=16):\n",
    "    # Create a shared counter using Value\n",
    "    counter = mp.Value('i', 0)\n",
    "    \n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create and start workers\n",
    "    workers = []\n",
    "    num_workers = os.cpu_count()//2\n",
    "    for _ in range(num_workers): \n",
    "        p = mp.Process(target=worker_loop, args=(counter, nops, n))\n",
    "        p.daemon = True \n",
    "        p.start()\n",
    "        workers.append(p)\n",
    "\n",
    "    # Wait until counter reaches NOPS\n",
    "    while True:\n",
    "        with counter.get_lock():\n",
    "            if counter.value >= nops:\n",
    "                break\n",
    "        time.sleep(0.01)  # Small sleep to avoid busy waiting\n",
    "\n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Clean up workers\n",
    "    for p in workers:\n",
    "        p.terminate()\n",
    "        \n",
    "    return elapsed_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envi",
   "language": "python",
   "name": "lingua_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
