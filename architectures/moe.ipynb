{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128, 256])\n"
     ]
    }
   ],
   "source": [
    "# I don't always annotate types because it's often obvious, but this is a relatively subtle \n",
    "# implementation where the index book-keeping etc is a bit involved, so I figured it'd be useful here \n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from typing import Tuple\n",
    "\n",
    "# TODO: \n",
    "    # allow support for top_k experts \n",
    "    # then put it into the train_rnn training loop \n",
    "        # we'll have to add z-loss/qk norm/ load balancing loss \n",
    "\n",
    "class Router(nn.Module): # [b, s, d] -> [b, s, M] learns to assign each token an expert \n",
    "    def __init__(self, d: int = 512, act: nn.Module = nn.GELU(), mult: int = 4, m: int = 16): \n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(d, mult * d)\n",
    "        self.act = act \n",
    "        self.w2 = nn.Linear(mult * d, m)\n",
    "\n",
    "    # [b, s, d] -> [b, s, m] automatically over last time of inputs\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor: \n",
    "        return self.w2(self.act(self.w1(x)))\n",
    "\n",
    "\n",
    "class MoEMLP(nn.Module): \n",
    "    def __init__(self, m: int = 16, c: float = 1.25, top_k: int = 2, d: int = 512, mult:int = 4, act: nn.Module = nn.GELU()): \n",
    "        super().__init__()\n",
    "        self.m = m\n",
    "        self.c = c\n",
    "        self.top_k = top_k\n",
    "        self.d = d\n",
    "        self.mult = mult\n",
    "\n",
    "        # we use nn.Parameter and not nn.Linear because we want a 3-tensor of params across all experts     \n",
    "            # you could also use an nn.ModuleList to track the nn.Linear across the m experts \n",
    "        self.mlp1 = nn.Parameter(torch.randn(m, d, d*mult) / (d ** 0.5)) # make sure scaled by fan_in so matmul outputs are O(1) indep of d\n",
    "        self.mlp2 = nn.Parameter(torch.randn(m, d*mult, d) / ((d*mult) ** 0.5)) \n",
    "        self.act = act \n",
    "\n",
    "        self.router = Router(d=d, act=act, mult=mult, m=m)\n",
    "\n",
    "    # [b, s, d] -> ([m, cap, d], [N, d], [N])\n",
    "        # first object is input to MLP computation along last dim \n",
    "        # second two tell us how the scatter was done so in gather() we can invert it back to [b, s, d]\n",
    "    def expert_scatter(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]: \n",
    "        b, s, d = x.shape \n",
    "        x_flat = x.view(-1, d) # [b*s, d]\n",
    "        c, m = self.c, self.m\n",
    "\n",
    "        cap = int(b*s*c//m) # token capacity for a single token \n",
    "        expert_inputs = torch.zeros(m, cap, d, device=x.device) # this is the object we seek to construct using our input x \n",
    "        \n",
    "        indices = torch.argmax(self.router(x), dim=-1).reshape(b*s) # [b, s, d] -> [b, s, m] -> [b, s] -> [b*s]\n",
    "        # # compute router logits and select top_k experts\n",
    "        # router_logits = self.router(x) # [b, s, m]\n",
    "        # # select top_k and get scores\n",
    "        # topk_logits, topk_indices = torch.topk(router_logits, k, dim=-1) # [b, s, k]\n",
    "        # topk_logits_flat = topk_logits.view(B, k)\n",
    "        # topk_indices_flat = topk_indices.view(B, k)\n",
    "        # # compute weights\n",
    "        # topk_weights = F.softmax(topk_logits_flat, dim=-1) # [B, k]\n",
    "\n",
    "        # # expand and weight inputs for each expert assignment\n",
    "        # weighted_src = x_flat.unsqueeze(1) * topk_weights.unsqueeze(2) # [B, k, d]\n",
    "        # assign_experts_flat = topk_indices_flat.reshape(-1) # [B*k]\n",
    "        # weighted_src_flat = weighted_src.reshape(-1, d) # [B*k, d]\n",
    "\n",
    "        one_hot = F.one_hot(indices, num_classes=m) # [b*s, m], we'll call b*s=B to represent \"effective batch size over tokens\"\n",
    "        counts = torch.cumsum(one_hot, dim=0) # [B, m] tells us how many tokens assigned to that expert seen so far (vertically)\n",
    "        \n",
    "        # this pos computation is one of the most subtle lines, make sure to understand it\n",
    "            # it uses clever indexing/broadcasting to take each index to the its index within [cap]\n",
    "            # which is precisely the count above less one because we're going from a count to a 0-idx\n",
    "            # here's how the indexing works\n",
    "                # an important torch rule: indexing tensor X with tensors of shape\n",
    "                    #  Y outputs a tensor of shape Y\n",
    "                # eg. X[1, 2, 3] the tensors Y are scalars, so we get a scalar, ie. the 1-2-3th entry in X\n",
    "\n",
    "                # here we want, for each row in range(b*s), the indices[row] element\n",
    "                # we want it to be [B] dim, so lets use range(B) and indices as our indices\n",
    "        pos = counts[torch.arange(b*s), indices] - 1\n",
    "\n",
    "        mask = pos < cap # these are the tokens we'll process at all, this is a [B] tensor of bools\n",
    "        selected_experts = indices[mask] # [N], where N is the number of indices that are true \n",
    "                                                # in the mask (data dependent)\n",
    "        \n",
    "        selected_pos = pos[mask] # [N]\n",
    "        selected_src = x_flat[mask]\n",
    "\n",
    "        flat_inputs = expert_inputs.view(m * cap, -1)\n",
    "        flat_idx = selected_experts * cap + selected_pos # for each selected idx, get its index in the target tensor\n",
    "        flat_idx = flat_idx.unsqueeze(-1).expand(-1, d) # [N] -> [N, d] so it has same shape as flat_inputs for .scatter_()\n",
    "        flat_inputs.scatter_(0, flat_idx, selected_src) # in place scatter of rows, everything was building up to be able to do this\n",
    "        expert_inputs = flat_inputs.view(m, cap, -1) \n",
    "\n",
    "        return (expert_inputs, flat_idx, mask) \n",
    "\n",
    "    # take scatter indices and the expert-wise outputs [m, cap, d] and \n",
    "    def expert_gather(self, outputs: torch.Tensor, mask: torch.Tensor, flat_idx: torch.Tensor, x: torch.Tensor) -> torch.Tensor: \n",
    "        b, s, d = x.shape\n",
    "        C, m = self.c, self.m \n",
    "        cap = int(b*s*C//m)\n",
    "\n",
    "        ## now we have outputs, gather them back into [b, s, d] \n",
    "        # gather has a similar api to scatter() and so we can re-use flat_idx to invert scatter()\n",
    "        flat_outputs = outputs.view(m*cap, d) # [m*cap, d]\n",
    "        gathered = torch.gather(flat_outputs, 0, flat_idx) # [N, d]\n",
    "        result = x.clone().reshape(b*s, d) # [b*s, d], we clone so that unprocessed tokens are pushed through \n",
    "        result[mask] = gathered # processed tokens overwritten by flat_outputs, which is output of MLPs\n",
    "        result = result.view(b, s, d) # want output to be [b, s, d], like input in an MLP layer \n",
    "        \n",
    "        return result \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor: \n",
    "        # assign each token to an expert and arrange tokens ready for expert computation\n",
    "        expert_inputs, flat_idx, mask = self.expert_scatter(x)\n",
    "\n",
    "        ## now do mlp computation on the inputs with a bmm along the num_experts axis (first, so treated as batch by default)\n",
    "        expert_outputs = torch.bmm(self.act(torch.bmm(expert_inputs, self.mlp1)), self.mlp2) # [m, cap, d] @ [m, d, d] -> [m, cap, d]\n",
    "\n",
    "        # use our scatter() indices to gather everything back into place into [b, s, d]\n",
    "        out = self.expert_gather(expert_outputs, mask, flat_idx, x) # [b, s, d]\n",
    "        \n",
    "        return out \n",
    "\n",
    "b, s, d, m, c = 16, 128, 256, 4, 1.25\n",
    "moe = MoEMLP(d=d, m=m, c=c)\n",
    "x = torch.randn(b, s, d)\n",
    "print(moe(x).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envi",
   "language": "python",
   "name": "lingua_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
